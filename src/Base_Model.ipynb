{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591fa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4a9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('headless');\n",
    "driver = webdriver.Chrome(executable_path=r'D:\\Downloads\\chromedriver_win32\\chromedriver.exe', options = options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00801789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep learning  (also known as deep structured ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convolutional Neural Networks</td>\n",
       "      <td>In deep learning, a convolutional neural netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>TensorFlow is a free and open-source software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Machine learning (ML) is the study of computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algorithms</td>\n",
       "      <td>In mathematics and computer science, an algori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Computer vision is an interdisciplinary scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep Reinforcement Learning</td>\n",
       "      <td>Deep reinforcement learning (deep RL) is a sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Computer science is the study of computation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Python</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Matlab</td>\n",
       "      <td>MATLAB (an abbreviation of \"MATrix LABoratory\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Recurrent Neural Networks</td>\n",
       "      <td>A recurrent neural network (RNN) is a class of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Django</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Java</td>\n",
       "      <td>Java (Indonesian: Jawa, Indonesian pronunciati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Keras</td>\n",
       "      <td>Keras is an open-source software library that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>PyTorch is an open source machine learning lib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Neural Networks</td>\n",
       "      <td>A neural network is a network or circuit of ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Edge Computing</td>\n",
       "      <td>Edge computing is a distributed computing para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>OpenCV (Open Source Computer Vision Library) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Scikit-Learn</td>\n",
       "      <td>Scikit-learn (formerly scikits.learn and also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>Natural language processing (NLP) is a subfiel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Object Detection</td>\n",
       "      <td>Object detection is a computer technology rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning (RL) is an area of mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Generative Adverserial Networks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             skills  \\\n",
       "0                     Deep Learning   \n",
       "1     Convolutional Neural Networks   \n",
       "2                        TensorFlow   \n",
       "3                  Machine Learning   \n",
       "4                        Algorithms   \n",
       "5                   Computer Vision   \n",
       "6       Deep Reinforcement Learning   \n",
       "7                  Computer Science   \n",
       "8                            Python   \n",
       "9                            Matlab   \n",
       "10        Recurrent Neural Networks   \n",
       "11                           Django   \n",
       "12                             Java   \n",
       "13                            Keras   \n",
       "14                          PyTorch   \n",
       "15                  Neural Networks   \n",
       "16                   Edge Computing   \n",
       "17                           OpenCV   \n",
       "18                     Scikit-Learn   \n",
       "19      Natural Language Processing   \n",
       "20                 Object Detection   \n",
       "21           Reinforcement Learning   \n",
       "22  Generative Adverserial Networks   \n",
       "\n",
       "                                              summary  \n",
       "0   Deep learning  (also known as deep structured ...  \n",
       "1   In deep learning, a convolutional neural netwo...  \n",
       "2   TensorFlow is a free and open-source software ...  \n",
       "3   Machine learning (ML) is the study of computer...  \n",
       "4   In mathematics and computer science, an algori...  \n",
       "5   Computer vision is an interdisciplinary scient...  \n",
       "6   Deep reinforcement learning (deep RL) is a sub...  \n",
       "7   Computer science is the study of computation, ...  \n",
       "8                                                 NaN  \n",
       "9   MATLAB (an abbreviation of \"MATrix LABoratory\"...  \n",
       "10  A recurrent neural network (RNN) is a class of...  \n",
       "11                                                NaN  \n",
       "12  Java (Indonesian: Jawa, Indonesian pronunciati...  \n",
       "13  Keras is an open-source software library that ...  \n",
       "14  PyTorch is an open source machine learning lib...  \n",
       "15  A neural network is a network or circuit of ne...  \n",
       "16  Edge computing is a distributed computing para...  \n",
       "17  OpenCV (Open Source Computer Vision Library) i...  \n",
       "18  Scikit-learn (formerly scikits.learn and also ...  \n",
       "19  Natural language processing (NLP) is a subfiel...  \n",
       "20  Object detection is a computer technology rela...  \n",
       "21  Reinforcement learning (RL) is an area of mach...  \n",
       "22                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = ['Deep Learning', 'Convolutional Neural Networks', 'TensorFlow', 'Machine Learning','Algorithms','Computer Vision','Deep Reinforcement Learning','Computer Science','Python','Matlab','Recurrent Neural Networks','Django','Java','Keras','PyTorch','Neural Networks','Edge Computing','OpenCV','Scikit-Learn','Natural Language Processing','Object Detection','Reinforcement Learning','Generative Adverserial Networks']\n",
    "skills_df = pd.read_csv(\"../data/skills.csv\")\n",
    "skills_df = skills_df.drop(columns = [\"Unnamed: 0\"])\n",
    "skills_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920af50f",
   "metadata": {},
   "source": [
    "#### Using Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b466ac5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "def bertTokens(text):\n",
    "    bertTokens = bert_tokenizer.tokenize(text)\n",
    "    return bertTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e58a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    try:\n",
    "        punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    except:\n",
    "        return \" \"\n",
    "    return punctuationfree\n",
    "\n",
    "def lower_case(text):\n",
    "    try:\n",
    "        lower = text.lower()\n",
    "    except:\n",
    "        print(\"Lower Case failed?\")\n",
    "        return \"\"\n",
    "    return lower\n",
    "\n",
    "def tokenization(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0c07758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learn']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatization([\"Learning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b8806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_summary</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>rare_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep learning  (also known as deep structured ...</td>\n",
       "      <td>deep learning  also known as deep structured l...</td>\n",
       "      <td>[deep, learning, also, known, as, deep, struct...</td>\n",
       "      <td>[deep, learn, also, know, as, deep, structure,...</td>\n",
       "      <td>[deep, learn, structure, broad, machine, metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Convolutional Neural Networks</td>\n",
       "      <td>In deep learning, a convolutional neural netwo...</td>\n",
       "      <td>in deep learning a convolutional neural networ...</td>\n",
       "      <td>[in, deep, learning, a, convolutional, neural,...</td>\n",
       "      <td>[in, deep, learn, a, convolutional, neural, ne...</td>\n",
       "      <td>[deep, learn, convolutional, neural, network, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TensorFlow</td>\n",
       "      <td>TensorFlow is a free and open-source software ...</td>\n",
       "      <td>tensorflow is a free and opensource software l...</td>\n",
       "      <td>[tensorflow, is, a, free, and, opensource, sof...</td>\n",
       "      <td>[tensorflow, be, a, free, and, opensource, sof...</td>\n",
       "      <td>[tensorflow, opensource, software, library, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Machine learning (ML) is the study of computer...</td>\n",
       "      <td>machine learning ml is the study of computer a...</td>\n",
       "      <td>[machine, learning, ml, is, the, study, of, co...</td>\n",
       "      <td>[machine, learn, ml, be, the, study, of, compu...</td>\n",
       "      <td>[machine, learn, ml, study, computer, algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Algorithms</td>\n",
       "      <td>In mathematics and computer science, an algori...</td>\n",
       "      <td>in mathematics and computer science an algorit...</td>\n",
       "      <td>[in, mathematics, and, computer, science, an, ...</td>\n",
       "      <td>[in, mathematic, and, computer, science, an, a...</td>\n",
       "      <td>[mathematic, computer, science, algorithm, lis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          skills  \\\n",
       "0                  Deep Learning   \n",
       "1  Convolutional Neural Networks   \n",
       "2                     TensorFlow   \n",
       "3               Machine Learning   \n",
       "4                     Algorithms   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Deep learning  (also known as deep structured ...   \n",
       "1  In deep learning, a convolutional neural netwo...   \n",
       "2  TensorFlow is a free and open-source software ...   \n",
       "3  Machine learning (ML) is the study of computer...   \n",
       "4  In mathematics and computer science, an algori...   \n",
       "\n",
       "                                       clean_summary  \\\n",
       "0  deep learning  also known as deep structured l...   \n",
       "1  in deep learning a convolutional neural networ...   \n",
       "2  tensorflow is a free and opensource software l...   \n",
       "3  machine learning ml is the study of computer a...   \n",
       "4  in mathematics and computer science an algorit...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [deep, learning, also, known, as, deep, struct...   \n",
       "1  [in, deep, learning, a, convolutional, neural,...   \n",
       "2  [tensorflow, is, a, free, and, opensource, sof...   \n",
       "3  [machine, learning, ml, is, the, study, of, co...   \n",
       "4  [in, mathematics, and, computer, science, an, ...   \n",
       "\n",
       "                                        lemma_tokens  \\\n",
       "0  [deep, learn, also, know, as, deep, structure,...   \n",
       "1  [in, deep, learn, a, convolutional, neural, ne...   \n",
       "2  [tensorflow, be, a, free, and, opensource, sof...   \n",
       "3  [machine, learn, ml, be, the, study, of, compu...   \n",
       "4  [in, mathematic, and, computer, science, an, a...   \n",
       "\n",
       "                                          rare_words  \n",
       "0  [deep, learn, structure, broad, machine, metho...  \n",
       "1  [deep, learn, convolutional, neural, network, ...  \n",
       "2  [tensorflow, opensource, software, library, ma...  \n",
       "3  [machine, learn, ml, study, computer, algorith...  \n",
       "4  [mathematic, computer, science, algorithm, lis...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_vocab = list(bert_tokenizer.vocab.keys())\n",
    "def rare_word_extractor(word_list):\n",
    "    rare_words = {}\n",
    "    for word in word_list:\n",
    "        if word in bert_vocab:\n",
    "            ind = bert_vocab.index(word)\n",
    "            if ind > 2500:\n",
    "                rare_words[word] = ind\n",
    "        else:\n",
    "            rare_words[word] = 0\n",
    "    rare_words_list = list(rare_words.keys())\n",
    "    return rare_words_list\n",
    "skills_df['clean_summary'] = skills_df['summary'].apply(lambda x:remove_punctuation(x)) \n",
    "skills_df['clean_summary'] = skills_df['clean_summary'].apply(lambda x:lower_case(x)) \n",
    "skills_df['tokens'] = skills_df['clean_summary'].apply(lambda x:tokenization(x)) \n",
    "skills_df['lemma_tokens'] = skills_df['tokens'].apply(lambda x:lemmatization(x)) \n",
    "skills_df['rare_words'] = skills_df['lemma_tokens'].apply(lambda x:rare_word_extractor(x)) \n",
    "skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99fe9f27",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa0 in position 35: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-db2203e714af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/web_history/synthetic_data_490 (1).csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# history = history.drop(columns = [\"Unnamed: 0\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\FT\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\FT\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\FT\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\FT\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Conda\\envs\\FT\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 35: invalid start byte"
     ]
    }
   ],
   "source": [
    "history = pd.read_csv(\"../data/web_history/with_labels.csv\")\n",
    "history = history.drop(columns = [\"Unnamed: 0\"])\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.LABEL.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.LABEL.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc6ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history['H1'] = pd.Series()\n",
    "history['H2'] = pd.Series()\n",
    "history['H3'] = pd.Series()\n",
    "history['p'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ef02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(url):\n",
    "    driver.get(url)\n",
    "    h1 = driver.find_elements_by_tag_name(\"h1\")\n",
    "    h2 = driver.find_elements_by_tag_name(\"h2\")\n",
    "    h3 = driver.find_elements_by_tag_name(\"h3\")\n",
    "    p = driver.find_elements_by_tag_name(\"p\")\n",
    "    return (h1,h2,h3,p)\n",
    "\n",
    "def extract_rare_words_from_sel_objects(tag):\n",
    "    rare_words = []\n",
    "    if tag != None:\n",
    "        for text in tag:\n",
    "            rare_words.append(rare_word_extractor(tokenization(lower_case(remove_punctuation(text.text)))))\n",
    "    return rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in history.iterrows():\n",
    "    print(\"URL INDEX: \", index, \"  LABEL: \", row['LABEL'] )\n",
    "    if index >= 1000:\n",
    "        break\n",
    "    \n",
    "    if row['LABEL'] != \"MISC\":\n",
    "        try:\n",
    "            (h1,h2,h3,p) = process_url(row['URL'])\n",
    "        except:\n",
    "            print(\"URL: \", row['URL'], \"\\n\\n\")\n",
    "            print(\"Index:\", index,\"Exception while processing url\")\n",
    "            row['H1'] = []\n",
    "            row['H2'] = []\n",
    "            row['H3'] = []\n",
    "            row['p'] = []\n",
    "            continue\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            rare_words_h1 = extract_rare_words_from_sel_objects(h1)\n",
    "        except:\n",
    "            print(\"Index:\", index,\"Exception while extracting h1\")\n",
    "            rare_words_h1 = []\n",
    "\n",
    "        try:\n",
    "            rare_words_h2 = extract_rare_words_from_sel_objects(h2)\n",
    "        except:\n",
    "            print(\"Index:\", index,\"Exception while extracting h2\")\n",
    "            rare_words_h2 = []\n",
    "\n",
    "        try:\n",
    "            rare_words_h3 = extract_rare_words_from_sel_objects(h3)\n",
    "        except:\n",
    "            print(\"Index:\", index,\"Exception while extracting h2\")\n",
    "            rare_words_h3 = []\n",
    "\n",
    "        try:\n",
    "            rare_words_p  = extract_rare_words_from_sel_objects(p)\n",
    "        except:      \n",
    "            print(\"Index:\", index,\"Exception while extracting h2\")\n",
    "            rare_words_p = []\n",
    "        \n",
    "        print(\"URL: \", row['URL'], \"\\n\\n\")\n",
    "        print(\"H1:  \",rare_words_h1, str(\"\\n\"))\n",
    "        print(\"H2:  \",rare_words_h2,str(\"\\n\"))\n",
    "        print(\"H3:  \",rare_words_h3,str(\"\\n\"))\n",
    "        print(\"P:  \",rare_words_p,str(\"\\n\"))\n",
    "    else:\n",
    "        rare_words_h1 = []\n",
    "        rare_words_h2 = []\n",
    "        rare_words_h3 = []\n",
    "        rare_words_p = []    \n",
    "    \n",
    "    row['H1'] = rare_words_h1\n",
    "    row['H2'] = rare_words_h2\n",
    "    row['H3'] = rare_words_h3\n",
    "    row['p'] = rare_words_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef3c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.H1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history[history['LABEL'] == \"WORK\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history[history['LABEL'] == \"MISC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aea39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history[history['LABEL'] == \"SHOPPING\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c61ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history[history['LABEL'] == \"TRAVEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history[history['LABEL'] == \"ENTERTAINMENT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b927c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1,h2,h3,p = process_url(\"https://www.youtube.com/watch?v=4I3gS1cmqe4\")\n",
    "h1,h2,h3,p = process_url(\"https://www.nytimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab1082",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rare_words_from_sel_objects(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rare_words_from_sel_objects(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rare_words_from_sel_objects(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a364f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_rare_words_from_sel_objects(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get(\"https://www.youtube.com/watch?v=4I3gS1cmqe4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ab30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = BeautifulSoup(data.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a1e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "html.findAll(text = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab51e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
